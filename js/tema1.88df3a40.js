(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["tema1"],{"002b":function(a,e,s){a.exports=s.p+"img/21.811ba9a8.svg"},"0162":function(a,e,s){a.exports=s.p+"img/22.d3e63590.svg"},"02c8":function(a,e,s){"use strict";s.r(e);var t=function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"curso-main-container pb-3"},[t("BannerInterno"),t("div",{staticClass:"container tarjeta tarjeta--blanca p-4 p-md-5 mb-5"},[a._m(0),t("div",{staticClass:"row justify-content-center mb-5"},[t("div",{staticClass:"col-lg-10"},[t("div",{staticClass:"bloque-texto-g color-primario p-3 p-sm-4 p-md-5"},[t("div",{staticClass:"bloque-texto-g__img",style:{"background-image":"url("+s("0fe3")+")"}}),a._m(1)])])]),t("div",{staticClass:"tarjeta p-5",staticStyle:{"background-color":"#f5fafe"}},[t("SlyderA",{attrs:{tipo:"b"}},[t("div",{staticClass:"row align-items-center"},[t("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[t("p",[a._v("La implementación o despliegue de modelos de "),t("em",[a._v("Machine learning")]),a._v(", ofrece a las empresas ventajas competitivas en el mercado y contexto actual, porque permite integrarlos con los demás módulos del ecosistema de la organización, generar valor agregado al negocio y maximizar la operación comercial.")])]),t("div",{staticClass:"col-md-6"},[t("img",{attrs:{src:s("2563"),alt:"Texto que describa la imagen"}})])]),t("div",{staticClass:"row align-items-center"},[t("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[t("p",[a._v("Los modelos de "),t("em",[a._v("Machine learning")]),a._v(" se pueden aplicar en todas las industrias; por ejemplo, en un sector como el comercio electrónico, donde los usuarios realizan compras a través de un sitio web, se implementan sugerencias o recomendaciones sobre los productos, de acuerdo con perfil del cliente, creado previamente, para maximizar la probabilidad de compra.")])]),t("div",{staticClass:"col-md-6"},[t("img",{attrs:{src:s("2965"),alt:"Texto que describa la imagen"}})])]),t("div",{staticClass:"row align-items-center"},[t("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[t("p",[a._v("Las implementaciones actuales necesitan que el flujo y procesamiento de la información sea sincrónico, es decir, que la información debe ser procesada al instante. Además, deben soportar el registro y consulta de grandes volúmenes de datos desde diferentes fuentes y tipos. ")])]),t("div",{staticClass:"col-md-6"},[t("img",{attrs:{src:s("19cb"),alt:"Texto que describa la imagen"}})])])])],1),t("Separador"),a._m(2),a._m(3),t("div",{staticClass:"row justify-content-center align-items-center mb-5"},[a._m(4),t("div",{staticClass:"col-lg-8",attrs:{"data-aos":"fade-left"}},[t("AcordionA",{staticClass:"mb-5",attrs:{tipo:"a","clase-tarjeta":"tarjeta tarjeta--a"}},[t("div",{attrs:{titulo:"Baja latencia"}},[t("p",[a._v("Un "),t("em",[a._v("pipeline")]),a._v(" permite consultas de datos a segundos de la fase final del proceso. Esto posibilita, a los científicos de datos, la creación de productos que se actualicen de forma inmediata.")])]),t("div",{attrs:{titulo:"Escalabilidad"}},[t("p",[a._v("Un "),t("em",[a._v("pipeline")]),a._v(" se puede utilizar tanto para procesar desde un centenar de datos, hasta miles o millones de ellos. Los sistemas de alto rendimiento no solo deben tener la capacidad de almacenar datos, sino también ofrecer el acceso para consultas de la totalidad de estos. ")])]),t("div",{attrs:{titulo:"Control de versiones"}},[t("p",[a._v("Un "),t("em",[a._v("pipeline")]),a._v(" podrá realizar cambios de versión sin interrumpir el proceso de los datos o generar pérdida de estos. ")])]),t("div",{attrs:{titulo:"Monitoreo"}},[t("p",[a._v("Los "),t("em",[a._v("pipelines")]),a._v(" deben generar alertas cuando en una fase, no se reciben datos o eventos; esto, con la finalidad que el analista de datos examine la anomalía y realice los correctivos pertinentes. ")])]),t("div",{attrs:{titulo:"<em> Testing</em>"}},[t("p",[a._v("Los "),t("em",[a._v("pipelines")]),a._v(" permiten las pruebas de datos cuando ingresan a una de sus fases, aun cuando no terminan en un base o lago de datos. ")])])])],1)]),a._m(5),a._m(6),t("div",{staticClass:"tarjeta p-5",staticStyle:{"background-color":"#fffcf2"}},[t("LineaTiempoC",{staticClass:"color-acento-contenido px-5",attrs:{"text-small":""}},[t("div",{staticClass:"row",attrs:{titulo:"Paso 1"}},[t("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[t("p",[a._v("Los lagos de datos proporcionan a los analistas la capacidad de procesar información desde distintos volúmenes de datos con altos niveles de tolerancia a fallas. Sin embargo, presentan complejidad en el acceso a los datos en comparación con las bases datos tradicionales, debido a la falta de herramientas o políticas de acceso. ")])]),t("div",{staticClass:"col-md-6"},[t("img",{attrs:{src:s("3659"),alt:""}})])]),t("div",{staticClass:"row",attrs:{titulo:"Paso 2"}},[t("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[t("p",[a._v("Los "),t("em",[a._v("pipelines")]),a._v(" son ampliamente usados en la automatización de flujos de trabajo, para ahorrar tiempo y aumentar la eficiencia. El conocimiento de los procesos que se van a automatizar, es importante en el diseño del "),t("em",[a._v("pipeline")]),a._v(", para que se pueda repetir en varios servicios y configurarse una sola vez. ")])]),t("div",{staticClass:"col-md-6"},[t("img",{attrs:{src:s("3659"),alt:""}})])]),t("div",{staticClass:"row",attrs:{titulo:"Paso 3"}},[t("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[t("p",[a._v("En el campo del "),t("em",[a._v("Data Science")]),a._v(", los "),t("em",[a._v("pipelines")]),a._v(" hacen que el preprocesamiento de los datos se realice muy rápido. Además, el "),t("em",[a._v("pipeline")]),a._v(" se puede reutilizar en las fases de pruebas o testeo, donde los datos aún no se han transformado o con nuevos datos que ingresen al modelo. ")])]),t("div",{staticClass:"col-md-6"},[t("img",{attrs:{src:s("3659"),alt:""}})])])])],1),a._m(7),t("div",{staticClass:"row justify-content-center mb-5"},[a._m(8),t("div",{staticClass:"col-lg-8",attrs:{"data-aos":"fade-left"}},[t("AcordionA",{staticClass:"mb-5",attrs:{tipo:"b","clase-tarjeta":"tarjeta "}},[t("div",{staticClass:"fst-italic",attrs:{titulo:"Paso1: Importar librerías "}},[t("p",[t("span",{staticClass:"r--v"},[a._v("# Se importan las librerías esenciales de pandas y numpy")]),t("br"),t("span",{staticClass:"r--m"},[a._v("import ")]),a._v("pandas "),t("span",{staticClass:"r--m"},[a._v("as ")]),a._v("pd"),t("br"),t("span",{staticClass:"r--m"},[a._v("import ")]),a._v("numpy "),t("span",{staticClass:"r--m"},[a._v("as ")]),a._v("np"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Se importa Pipeline")]),t("br"),t("span",{staticClass:"r--m"},[a._v("from ")]),a._v("sklearn.pipeline "),t("span",{staticClass:"r--m"},[a._v("import ")]),a._v("Pipeline"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Se importan los requisitos para el funcionamiento del modelo")]),t("br"),t("span",{staticClass:"r--m"},[a._v("from")]),a._v(" sklearn.preprocessing "),t("span",{staticClass:"r--m"},[a._v("import")]),a._v(" StandardScaler"),t("br"),t("span",{staticClass:"r--m"},[a._v("from")]),a._v(" sklearn.linear_model "),t("span",{staticClass:"r--m"},[a._v("import")]),a._v(" LinearRegression"),t("br"),t("span",{staticClass:"r--m"},[a._v("from")]),a._v(" sklearn.model_selection "),t("span",{staticClass:"r--m"},[a._v("import")]),a._v(" train_test_split")])]),t("div",{attrs:{titulo:"Paso 2: Crear conjunto de datos"}},[t("p",[a._v("Ahora crearemos un conjunto de datos para el ejemplo:")]),t("p",{staticClass:"fst-italic"},[t("span",{staticClass:"r--v"},[a._v("# Creación aleatoria de un Dataframe")]),t("br"),a._v("Caracteristica1 = np.random.randint"),t("span",{staticClass:"r--v"},[a._v("(10,99, 999)")]),t("br"),a._v("Caracteristica2 = np.random.choice(np.random.randint"),t("span",{staticClass:"r--v"},[a._v("(15,200), 999)")]),t("br"),a._v("a = np.random.randn"),t("span",{staticClass:"r--v"},[a._v("(999)")]),t("br"),a._v("y1 = "),t("span",{staticClass:"r--v"},[a._v("0.195")]),t("br"),a._v("y2 = "),t("span",{staticClass:"r--v"},[a._v("0.377")]),t("br"),a._v("dataframe = pd.DataFrame({ "),t("span",{staticClass:"r--r"},[a._v("‘grupo’")]),a._v(": np.random.choice([10, 20, 30], 999),"),t("br"),t("span",{staticClass:"r--r"},[a._v("‘Caracteristica1’")]),a._v(": Caracteristica1 , "),t("span",{staticClass:"r--r"},[a._v("‘ Caracteristica2’")]),a._v(": Caracteristica2,"),t("br"),t("span",{staticClass:"r--r"},[a._v("‘Tipo’")]),a._v(": np.random.choice(["),t("span",{staticClass:"r--v"},[a._v("11, 12, 21, 22, 3")]),a._v("], "),t("span",{staticClass:"r--v"},[a._v("999")]),a._v("),"),t("br"),t("span",{staticClass:"r--r"},[a._v("‘Resultado’")]),a._v(": ((Caracteristica1*y1) + (Caracteristica2*y2) + a) })")])]),t("div",{attrs:{titulo:"Paso 3: Aplicar modelo de regresión"}},[t("p",[a._v("El conjunto de datos creado, tiene la estructura a continuación. A estos datos se les aplicará un modelo de regresión, con el fin de predecir la variable resultante.")]),t("div",{staticClass:"row justify-content-center mb-5"},[t("div",{staticClass:"col-lg-6"},[t("img",{attrs:{src:s("7aeb"),alt:""}})])])]),t("div",{attrs:{titulo:"Paso 4: Crear lista de tuplas"}},[t("p",[a._v("Para crear "),t("em",[a._v("pipelines")]),a._v(", es indispensable conocer previamente los pasos que conforman el proceso; la notación es “(nombre_del_paso', Instancia() )”, donde el primer parámetro es el nombre del paso y el segundo, su respectiva instancia. "),t("br"),t("br"),a._v("Luego de conocer los pasos del "),t("em",[a._v("pipeline")]),a._v(", se creará una lista de tuplas:")]),t("p",{staticClass:"fst-italic"},[t("span",{staticClass:"r--v"},[a._v("# Crear los pasos a realizar ")]),t("br"),a._v("pasos = [("),t("span",{staticClass:"r--r"},[a._v("‘Estandar’")]),a._v(", StandardScaler()), "),t("br"),t("span",{staticClass:"ms-5"},[a._v("("),t("span",{staticClass:"r--r"},[a._v("‘Regresion_Lineal’")]),a._v(", LinearRegression()) ")]),a._v("]")])]),t("div",{attrs:{titulo:"Paso 5: Crear objeto"}},[t("p",[a._v("Seguidamente, se crea el objeto para el "),t("em",[a._v("pipeline")]),a._v(" o tubería."),t("br"),t("br"),t("em",[a._v("tuberia = Pipeline(pasos)")])])]),t("div",{attrs:{titulo:"Paso 6: Crear <em>dataframe</em> de entrenamiento"}},[t("p",[a._v("La siguiente fase no hace parte de la creación del "),t("em",[a._v("pipeline")]),a._v(", pero será necesaria para la articulación e implantación del modelo.")]),t("p",{staticClass:"fst-italic"},[t("span",{staticClass:"r--v"},[a._v("# Se crea un nuevo dataframe para el entrenamiento del modelo")]),t("br"),a._v("df_train = dataframe"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("#Se separa la columna que contiene la variable objetivo “Resultado”")]),t("br"),a._v("X = np.array(df_train.drop(["),t("span",{staticClass:"r--r"},[a._v("‘Resultado’")]),a._v("],1))"),t("br"),a._v("y = np.array(df_train["),t("span",{staticClass:"r--r"},[a._v("‘Resultado’")]),a._v("])"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("#Se dividen los datos en entrenamiento y prueba")]),t("br"),a._v("X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = "),t("span",{staticClass:"r--v"},[a._v("0.2")]),a._v(", random_state = "),t("span",{staticClass:"r--v"},[a._v("10")]),a._v(")"),t("br"),t("span",{staticClass:"r--v"},[a._v("#Se usa 20% de datos para prueba y una semilla de 10.")])])]),t("div",{attrs:{titulo:"Uso del <em>pipeline</em>"}},[t("p",[a._v("Finalmente, se hace uso del "),t("em",[a._v("pipeline")]),a._v(" en los procesos de entrenamiento, medición de métricas y predicción.")]),t("p",{staticClass:"fst-italic"},[t("span",{staticClass:"r--v"},[a._v("# Pipeline para el entrenamiento")]),t("br"),a._v("tuberia.fit(X,y)"),t("br"),a._v('(span.r--v="", #="", Pipeline="", para="", el="", Score="") '),t("br"),a._v("tuberia.score(X, y)"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Pipeline para la predicción")]),a._v('(span.r--v="", #="", Pipeline="", para="", el="", Score="") '),t("br"),a._v("tuberia.predict(X_test)")])])])],1)]),a._m(9),t("div",{staticClass:"h3",attrs:{id:"t_1_2"}},[a._v("1.2 Optimización de la implementación de modelos")]),a._m(10),t("div",{staticClass:"row justify-content-center mb-5"},[t("div",{staticClass:"col-lg-8",attrs:{"data-aos":"fade-right"}},[t("TabsA",{staticClass:"color-acento-botones mb-5"},[t("div",{staticClass:"tarjeta p-4",staticStyle:{"background-color":"#dbeefe"},attrs:{titulo:"Primera razón"}},[t("p",[a._v("Librerías populares de "),t("em",[a._v("Machine learning")]),a._v(", como Scikit-Learn, no admiten campos faltantes o datos categóricos en sus entradas, por lo tanto, esos campos deben ser imputados con algún valor que los represente, como la media o la moda.")])]),t("div",{staticClass:"tarjeta p-4",staticStyle:{"background-color":"#dbeefe"},attrs:{titulo:"Segunda razón"}},[t("p",[a._v("Algunos algoritmos, como la regresión lineal, las redes neuronales y el K vecino más cercano, son sensibles a la escala variable, de modo que todos los valores de una variable deben tener la misma unidad o métrica. Por ejemplo, en un campo que contiene datos de tiempo, todos los registros deben entenderse ya sea por días, semanas, meses o años, pero no deben contener diferentes escalas. ")])]),t("div",{staticClass:"tarjeta p-4",staticStyle:{"background-color":"#dbeefe"},attrs:{titulo:"Tercera razón"}},[t("p",[a._v("Algunos algoritmos, como la regresión lineal, son muy sensibles a valores atípicos. Por ejemplo, si tenemos una base de datos con información sobre el costo de las casas en una región del país y uno de sus registros tiene un valor excesivamente bajo, este valor se cataloga como atípico y debe tratarse, ya sea con una imputación o una eliminación.")])]),t("div",{staticClass:"tarjeta p-4",staticStyle:{"background-color":"#dbeefe"},attrs:{titulo:"Cuarta razón"}},[t("p",[a._v("Se pueden obtener muchos datos útiles de los datos en crudo. Por ejemplo, fechas, series temporales, transacciones, entre otros.")])])])],1),a._m(11)]),a._m(12),t("AcordionA",{staticClass:"mb-5",attrs:{tipo:"a","clase-tarjeta":"tarjeta tarjeta--a"}},[t("div",{attrs:{titulo:"Imputación de datos faltantes "}},[t("p",[a._v("Este proceso consiste en el reemplazo de valores faltantes de la base de datos, por números. Estos números, por lo general, son estimaciones estadísticas. A continuación, se muestra un ejemplo de esta técnica empleando la clase SimpleImputer de librería Scikit-Learn:")]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-md-5 mb-4 mb-md-0"},[t("p",{staticClass:"fst-italic"},[t("span",{staticClass:"r--v"},[a._v("# Se importan las librerias requeridas para el proceso de imputación")]),t("br"),t("span",{staticClass:"r--m"},[a._v("from")]),a._v(" sklearn.impute "),t("span",{staticClass:"r--m"},[a._v("import")]),a._v(" SimpleImputer"),t("br"),t("span",{staticClass:"r--m"},[a._v("import")]),a._v(" numpy "),t("span",{staticClass:"r--m"},[a._v("as")]),a._v(" np"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Se crea una matriz de ejemplo con datos que contiene valores vacios")]),t("br"),a._v("matriz = [["),t("span",{staticClass:"r--v"},[a._v("3")]),a._v(", "),t("span",{staticClass:"r--v"},[a._v("8")]),a._v("], [np.nan, "),t("span",{staticClass:"r--v"},[a._v("6")]),a._v("], ["),t("span",{staticClass:"r--v"},[a._v("1")]),a._v(", "),t("span",{staticClass:"r--v"},[a._v("5")]),a._v("]]"),t("br"),a._v("print(matriz)"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("#Salida:")]),a._v(" [[3, 8], [nan, 6], [1, 5]]"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# se crea el objeto de imputación con la media estadística")]),t("br"),a._v("imputacion = SimpleImputer(missing_values=np.nan, strategy="),t("span",{staticClass:"r--r"},[a._v("‘mean’")]),a._v(")"),t("br"),t("br"),a._v("# Se imputan los valores vacíos que encuentra en la matriz "),t("br"),a._v("imputacion = imputacion.fit(matriz)"),t("br"),a._v("# Se transforman los datos de la matriz"),t("br"),a._v("matriz = imputacion.transform(matriz)"),t("br"),t("br"),a._v("# se muestra la matriz transformada"),t("br"),t("span",{staticClass:"r--m"},[a._v("print")]),a._v("(matriz)"),t("br"),t("br"),a._v("#Salida: "),t("br"),t("br"),a._v("# [[3. 8.]"),t("br"),a._v("# [2. 6.]"),t("br"),a._v("# [1. 5.]]")])]),t("div",{staticClass:"col-md-7"},[t("figure",[t("img",{attrs:{src:s("b080"),alt:"Texto que describa la imagen"}})])])])]),t("div",{attrs:{titulo:"Discretización "}},[t("p",[a._v("Este proceso ordena los valores de una variable en intervalos, con el fin de obtener un número limitado de estados. Generalmente, los analistas de datos crean intervalos de igual ancho o frecuencia, para clasificar los valores de las variables. Por ejemplo, cuando se requiere ordenar el campo de edades de una base de datos en los estados de niño, adolescente, adulto y anciano. Modelos como los árboles de decisión y Naive Bayes, tienen mejor rendimiento trabajando con valores discretos. A continuación, se muestra un ejemplo de esta técnica usando la librería Pandas de Python.")]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-md-5 mb-4 mb-md-0"},[t("p",{staticClass:"fst-italic"},[t("span",{staticClass:"r--v"},[a._v("# En el ejemplo siguiente se discretiza la variable “edad”]"),t("br"),a._v("# en un conjunto de datos, utilizando el método de intervalos iguales. "),t("br"),a._v("# Se utilizarán tres intervalos:"),t("br"),t("br"),a._v("# 12-21 años"),t("br"),a._v("# 22-32 años"),t("br"),a._v("# 33-75 años"),t("br"),t("br"),a._v("# Se importa la librería pandas")]),t("br"),t("span",{staticClass:"r--m"},[a._v("import")]),a._v(" pandas"),t("span",{staticClass:"r--m"},[a._v("as")]),a._v(" pd"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Se crea un set de datos con valores aleatorios")]),t("br"),a._v("datos = pd.DataFrame({"),t("span",{staticClass:"r--r"},[a._v("‘edad’")]),a._v(": ["),t("span",{staticClass:"r--v"},[a._v("19, 50, 28, 21, 29, 33, 24, 45, 45, 52,")]),t("br"),t("span",{staticClass:"r--v"},[a._v("51, 52, 28, 53, 55, 33, 64, 39, 22")]),a._v("]})"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Se discretiza la variable “edad”")]),t("br"),a._v("datos["),t("span",{staticClass:"r--r"},[a._v("“edad_discreta”")]),a._v("] = pd.cut(datos["),t("span",{staticClass:"r--r"},[a._v("“edad”")]),a._v("], bins=["),t("span",{staticClass:"r--v"},[a._v("12, 21, 33, 75")]),a._v("],"),t("br"),a._v("labels=["),t("span",{staticClass:"r--r"},[a._v("“12-21”, “22-32”, “33-75”")]),a._v("])"),t("br"),t("br"),t("span",{staticClass:"r--r"},[a._v("# Se muestran los 5 primeros valores de forma discreta")]),t("br"),t("span",{staticClass:"r--m"},[a._v("print")]),a._v("(datos["),t("span",{staticClass:"r--r"},[a._v("“edad_discreta”")]),a._v("].head("),t("span",{staticClass:"r--v"},[a._v("5")]),a._v("))"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Salida:")]),t("br"),t("br"),a._v("#0 12-21"),t("br"),a._v("#1 33-75"),t("br"),a._v("#2 22-32"),t("br"),a._v("#3 12-21"),t("br"),a._v("#4 22-32")])]),t("div",{staticClass:"col-md-7"},[t("figure",[t("img",{attrs:{src:s("0663"),alt:"Texto que describa la imagen"}})])])])]),t("div",{attrs:{titulo:"Codificación de variables categóricas "}},[t("p",[a._v("Las variables categóricas son aquellas que tienen nombres de categorías y no números, como valores; por ejemplo, los valores de la variable “estado civil” pueden ser soltero, divorciado, casado y otros. Es habitual que los analistas de datos agrupen los valores poco comunes o raros en la categoría llamada otros. A continuación, se muestra un ejemplo de esta técnica empleando la clase LabelEncoder de librería Scikit-Learn:")]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-md-5 mb-4 mb-md-0"},[t("p",{staticClass:"fst-italic"},[t("span",{staticClass:"r--v"},[a._v("# Se importan las librerías")]),t("br"),t("span",{staticClass:"r--m"},[a._v("import")]),a._v(" pandas "),t("span",{staticClass:"r--m"},[a._v("as")]),a._v(" pd"),t("br"),t("span",{staticClass:"r--m"},[a._v("from")]),a._v(" sklearn.preprocessing "),t("span",{staticClass:"r--m"},[a._v("import")]),a._v(" LabelEncoder"),t("br"),t("br"),t("span",{staticClass:"r--r"},[a._v("# Se crea un dataframe con los nombres de las categorías")]),t("br"),a._v("dataframe = pd.DataFrame({"),t("span",{staticClass:"r--r"},[a._v("“variable”")]),a._v(": ["),t("span",{staticClass:"r--r"},[a._v("‘soltero’,’casado’,’soltero’,’divorciado’,’casado’")]),a._v("]})"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Se crea el objeto de codificación")]),t("br"),a._v("codificacion = LabelEncoder()"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Se codifican las variables")]),t("br"),a._v("dataframe["),t("span",{staticClass:"r--r"},[a._v("“variable”")]),a._v("] = codificacion.fit_transform(dataframe["),t("span",{staticClass:"r--r"},[a._v("“variable”")]),a._v("])"),t("br"),t("br"),t("span",{staticClass:"r--v"},[a._v("# Se muestra el dataframe codificado")]),t("br"),t("span",{staticClass:"r--m"},[a._v("print")]),a._v("(dataframe)"),t("br"),t("br"),a._v("# Salida: "),t("br"),t("br"),a._v("# variable"),t("br"),a._v("#0 2"),t("br"),a._v("#1 0"),t("br"),a._v("#2 2"),t("br"),a._v("#3 1"),t("br"),a._v("#4 0")])]),t("div",{staticClass:"col-md-7"},[t("figure",[t("img",{attrs:{src:s("9bbd"),alt:"Texto que describa la imagen"}})])])])])]),a._m(13),a._m(14),t("div",{staticClass:"row justify-content-center mb-5"},[t("div",{staticClass:"col-lg-10"},[t("div",{staticClass:"tarjeta p-3 mb-5",staticStyle:{"background-color":"#c4e4fe"}},[t("div",{staticClass:"row justify-content-around align-items-center"},[a._m(15),t("div",{staticClass:"col"},[t("div",{staticClass:"row justify-content-between align-items-center"},[a._m(16),t("div",{staticClass:"col-sm-auto"},[t("a",{staticClass:"boton color-acento-botones",attrs:{href:a.obtenerLink("downloads/Anexos_videoclase.zip"),target:"_blank"}},[t("span",[a._v("Descargar")]),t("i",{staticClass:"fas fa-file-download"})])])])])])])])]),a._m(17),a._m(18),a._m(19),t("div",{staticClass:"row justify-content-center mb-5"},[a._m(20),t("div",{staticClass:"col-lg-8",attrs:{"data-aos":"fade-left"}},[t("LineaTiempoD",{staticClass:"color-primario"},[t("div",{attrs:{numero:"1",titulo:"Estándares "}},[t("p",[a._v("Los estándares para exportación de modelos de "),t("em",[a._v("Machine learning")]),a._v(" son la solución para su portabilidad y disponibilidad, independientemente de la plataforma donde se desplieguen. Entre los estándares más populares se encuentran:")]),t("ul",{staticClass:"lista-ul"},[t("li",[t("i",{staticClass:"fas fa-angle-right"}),t("p",{staticClass:"mb-0"},[t("b",[a._v("PMML:")]),a._v(" El estándar PMML (Predictive Model Markup Language), es un lenguaje de marcado que tiene como base a XML. Fue desarrollado por el Grupo de Minería de Datos (DMG), con el fin de soportar modelos estadísticos y de minería de datos. ")])]),t("li",[t("i",{staticClass:"fas fa-angle-right"}),t("p",{staticClass:"mb-0"},[t("b",[a._v("ONNX:")]),a._v(" El estándar ONNX (Open Neural Network Exchange) es idóneo para los modelos de "),t("em",[a._v("Deep learning")]),a._v(", porque produce un diagrama de la red que se guarda en un archivo binario y puede ser utilizado en distintas plataformas. ")])])])]),t("div",{attrs:{numero:"2",titulo:"Diseño del modelo"}},[t("p",[a._v("En los ambientes de producción no importa la plataforma en que se diseñó y construyó un modelo de "),t("em",[a._v("Machine learning")]),a._v(", ya que se debe garantizar que los componentes desarrollados puedan consumirse desde distintas plataformas, por ejemplo, que un modelo diseñado en Python pueda ser utilizado desde una aplicación con sistema operativo Android.")])]),t("div",{attrs:{numero:"3",titulo:"Ambientes de producción"}},[t("p",[a._v("La ciencia de datos generalmente se realiza sobre Python y sus librerías, sin embargo, en los ambientes de producción su uso no es recomendable, debido a que su baja escalabilidad lo limita para procesar grandes cantidades de datos. El entrenamiento de modelos con "),t("em",[a._v("petabytes")]),a._v(" de información, requiere de plataformas de "),t("em",[a._v("Big data")]),a._v(" como Hadoop, Spark, Flink, etc., las cuales son preferidas por los sistemas de producción de las organizaciones. ")])]),t("div",{attrs:{numero:"4",titulo:"Arquitectura"}},[t("p",[a._v("Los sistemas de "),t("em",[a._v("Machine learning")]),a._v(", tienen los siguientes desafíos en los diseños de su arquitectura: ")]),t("ul",{staticClass:"lista-ul"},[t("li",[t("i",{staticClass:"fas fa-angle-right"}),t("p",{staticClass:"mb-0"},[t("b",[a._v("Python")]),a._v(" es ideal para la implementación de modelos de alto rendimiento; sin embargo, requiere aumentar su capacidad de procesamiento y escalabilidad, para el entrenamiento de modelos con grandes volúmenes de datos.")])]),t("li",[t("i",{staticClass:"fas fa-angle-right"}),t("p",{staticClass:"mb-0"},[a._v("Las plataformas como Hadoop, Spark o Flink, aunque solucionan el inconveniente de la escalabilidad, no son adecuadas para integraciones sincrónicas, donde el cliente requiere de altos rendimientos en los modelos. ")])])])])])],1)])],1)],1)},i=[function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("div",{staticClass:"titulo-principal color-acento-contenido"},[s("div",{staticClass:"titulo-principal__numero"},[s("span",[a._v("1")])]),s("h1",[a._v("Introducción a la implementación de modelos de "),s("em",[a._v("Machine Learning")])])])},function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("div",{staticClass:"bloque-texto-g__texto p-4"},[s("p",{staticClass:"mb-0"},[a._v("El proceso de implementación de modelos de "),s("em",[a._v("Machine Learning")]),a._v(", consiste en pasar, un modelo previamente construido, hacia un ambiente donde estará disponible para ser accedido por los usuarios o clientes. Este ambiente, por lo general, está alojado en la nube y a través de Internet, proporciona disponibilidad para que se pueda usar en tiempo real. ")])])},function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("div",{staticClass:"h3",attrs:{id:"t_1_1"}},[a._v("1.1 Implementación de "),s("em",[a._v("Pipelines")])])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"row justify-content-center align-items-center mb-5"},[t("div",{staticClass:"col-lg-7 mb-lg-0 mb-3",attrs:{"data-aos":"fade-right"}},[t("p",[a._v("Un "),t("em",[a._v("pipeline")]),a._v(" de datos es un conjunto de fases y herramientas tecnológicas que se integran para realizar los procesos de transformación de los datos, desde el inicio hasta su almacenamiento persistente. La creación de "),t("em",[a._v("pipelines")]),a._v(", es un componente central de la ciencia de datos que permite crear aplicaciones para recopilar datos de millones de usuarios y procesar los resultados casi en tiempo real. ")]),t("p",[a._v("Así mismo, los "),t("em",[a._v("pipelines")]),a._v(" se entienden como una composición de tareas, donde cada una toma un conjunto de entradas y produce un conjunto de salidas. Estas canalizaciones combinan las tareas en formas especificadas por el analista de datos que las crea. (Cedeno, 2020)")]),t("p",[a._v("Generalmente, los "),t("em",[a._v("pipelines")]),a._v(" canalizan los datos hacia repositorios o lagos de datos, que se encuentran en la nube, como Hadoop, S3 de AWS o bases de datos relacionales como Redshift. ")]),t("p",[a._v("Los "),t("em",[a._v("pipelines")]),a._v(" tienen las siguientes propiedades:")])]),t("div",{staticClass:"col-lg-5 col-6",attrs:{"data-aos":"fade-left"}},[t("img",{attrs:{src:s("f388"),alt:""}})])])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"col-lg-4 col-6 mb-lg-0 mb-3",attrs:{"data-aos":"fade-right"}},[t("img",{attrs:{src:s("23f1"),alt:""}})])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"row justify-content-center align-items-center mb-5"},[t("div",{staticClass:"col-lg-2 col-5 mb-lg-0 mb-3",attrs:{"data-aos":"fade-right"}},[t("img",{attrs:{src:s("4e3e"),alt:""}})]),t("div",{staticClass:"col-lg-10"},[t("p",{staticClass:"mb-0"},[a._v("Uno de los estándares más comunes para el almacenamiento de datos masivos en la industria es el data "),t("em",[a._v("lake")]),a._v(" o lago de datos, el cual permite almacenar datos semiestructurados en una base de datos distribuida y ejecutar procesos ETL para extraer los datos más relevantes y almacenarlos en las bases de datos de análisis. Se pueden usar diferentes herramientas para la base de datos distribuida, como Hadoop, Cosmos o S3.")])])])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"row justify-content-center mb-5"},[t("div",{staticClass:"col-lg-10"},[t("img",{attrs:{src:s("c589"),alt:""}})])])},function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("p",{staticClass:"mb-5",attrs:{"data-aos":"fade-right"}},[a._v("A continuación, se muestra un ejemplo de la creación de un "),s("em",[a._v("pipeline")]),a._v(" usando: el lenguaje de programación Python, la librería Scikit Learn y la herramienta Google Colab. ")])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"col-lg-4 col-6",attrs:{"data-aos":"fade-right"}},[t("img",{attrs:{src:s("a268"),alt:""}})])},function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("p",{staticClass:"mb-4",attrs:{"data-aos":"fade-right"}},[a._v("En el ejemplo anterior se muestra la implementación de un "),s("em",[a._v("pipeline")]),a._v(" para realizar el proceso de entrenamiento del modelo y la predicción de la variable resultado con el algoritmo de regresión lineal. ")])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"row justify-content-center mb-5"},[t("div",{staticClass:"col-lg-3 col-6 mb-lg-0 mb-3",attrs:{"data-aos":"fade-right"}},[t("img",{attrs:{src:s("1bd5"),alt:""}})]),t("div",{staticClass:"col-lg-9",attrs:{"data-aos":"fade-left"}},[t("p",[a._v("Generalmente, las organizaciones cuentan con datos sin procesar, recopilados y almacenados en bases de datos. Estos datos no son adecuados para entrenar modelos de "),t("em",[a._v("Machine learning")]),a._v(" o como insumo a modelos ya existentes, para generar una predicción. El ingeniero de datos, por su parte, debe realizar una serie de transformaciones antes que los algoritmos de "),t("em",[a._v("Machine learning")]),a._v(" puedan utilizar estas variables. A estas transformaciones, se les conoce como ingeniería de funciones. "),t("br"),t("br"),a._v("La ingeniería de funciones utiliza el conocimiento que el experto del dominio tiene de los datos para crear métodos que realicen imputación de datos faltantes, codificación de variables categóricas, transformación de variables numéricas y creación de nuevas características, entre otras. Estos métodos deben devolver un conjunto de datos idóneo para el entrenamiento de los modelos de aprendizaje automático. "),t("br"),t("br"),a._v("Los científicos de datos dedican hasta el 60 % del tiempo en tareas relacionadas con la ingeniería de funciones o características. Este tiempo se justifica por las siguientes razones:")])])])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"col-lg-4 col-6",attrs:{"data-aos":"fade-left"}},[t("img",{attrs:{src:s("a6a0"),alt:""}})])},function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("p",{staticClass:"mb-4",attrs:{"data-aos":"fade-right"}},[a._v("En la creación de nuevas características para la optimización de los modelos de "),s("em",[a._v("Machine learning")]),a._v(", se destacan los siguientes procesos de la ingeniería de funciones:")])},function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("p",{staticClass:"mb-4",attrs:{"data-aos":"fade-right"}},[a._v("Para una mejor comprensión del tema "),s("em",[a._v("Machine learning")]),a._v(", se le invita a ver el siguiente video: ")])},function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("figure",{staticClass:"mb-5"},[s("div",{staticClass:"video"},[s("iframe",{attrs:{width:"560",height:"315",src:"https://www.youtube.com/embed/tkeCwwPOVIU",title:"YouTube video player",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:""}})])])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"col-3 col-sm-2 col-lg-2"},[t("img",{staticClass:"px-3",attrs:{src:s("2b7a")}})])},function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("div",{staticClass:"col mb-3 mb-sm-0"},[s("p",[a._v("Para realizar los ejercicios explicados en la videoclase, descargue los archivos que se usarán en la práctica:"),s("br"),s("br"),s("b",[a._v("Anexos:")])]),s("ol",{staticClass:"lista-ol--cuadro d-flex justify-content-between"},[s("li",[s("div",{staticClass:"lista-ol--cuadro__vineta",staticStyle:{"background-color":"#ffb30b"}},[s("span",{staticStyle:{color:"black"}},[a._v("1")])]),a._v("Datos_A.xlsx")]),s("li",[s("div",{staticClass:"lista-ol--cuadro__vineta",staticStyle:{"background-color":"#ffb30b"}},[s("span",{staticStyle:{color:"black"}},[a._v("2")])]),a._v("Datos_B.xlsx")]),s("li",[s("div",{staticClass:"lista-ol--cuadro__vineta",staticStyle:{"background-color":"#ffb30b"}},[s("span",{staticStyle:{color:"black"}},[a._v("3")])]),a._v("Optimizacion_de_Dataset.ipynb")])])])},function(){var a=this,e=a.$createElement,s=a._self._c||e;return s("div",{staticClass:"h3",attrs:{id:"t_1_3"}},[a._v("1.3 Arquitectura del sistema de "),s("em",[a._v("Machine learning")])])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"row justify-content-center mb-5"},[t("div",{staticClass:"col-lg-2 col-5 mb-lg-0 mb-3",attrs:{"data-aos":"fade-right"}},[t("img",{attrs:{src:s("002b"),alt:""}})]),t("div",{staticClass:"col-lg-10",attrs:{"data-aos":"fade-left"}},[t("p",[a._v("Los modelos de "),t("em",[a._v("Machine learning")]),a._v(" se crean utilizando distintos lenguajes de programación como, Java, Python, R, Julia, entre otros. A su vez, cada lenguaje cuenta con librerías de apoyo para su construcción; por ejemplo, Python tiene Scikit-learn, TensorFlow, PyTorch, etc. De acuerdo con los diversos lenguajes y librerías con los que se pueden crear los modelos de "),t("em",[a._v("Machine learning")]),a._v(", es necesario exportarlos en un estándar que funcione en cualquier plataforma.")])])])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"row justify-content-center mb-5"},[t("div",{staticClass:"col-lg-6"},[t("img",{attrs:{src:s("0162"),alt:""}})])])},function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("div",{staticClass:"col-lg-4 col-6 mb-lg-0 mb-3",attrs:{"data-aos":"fade-right"}},[t("img",{attrs:{src:s("1763"),alt:""}})])}],r={name:"Tema1",components:{},data:function(){return{}},mounted:function(){var a=this;this.$nextTick((function(){a.$aosRefresh()}))},updated:function(){this.$aosRefresh()}},o=r,n=s("2877"),l=Object(n["a"])(o,t,i,!1,null,null,null);e["default"]=l.exports},"0663":function(a,e,s){a.exports=s.p+"img/18.69e3ecde.svg"},"0fe3":function(a,e,s){a.exports=s.p+"img/1.e64aa4c1.jpg"},1763:function(a,e,s){a.exports=s.p+"img/23.456dd476.png"},"19cb":function(a,e,s){a.exports=s.p+"img/4.52b12b36.png"},"1bd5":function(a,e,s){a.exports=s.p+"img/15.9272eab4.svg"},"23f1":function(a,e,s){a.exports=s.p+"img/6.19a64776.png"},2563:function(a,e,s){a.exports=s.p+"img/2.8dc96fc5.svg"},2965:function(a,e,s){a.exports=s.p+"img/3.97f5db64.png"},"2b7a":function(a,e,s){a.exports=s.p+"img/20.60df38cf.svg"},3659:function(a,e,s){a.exports=s.p+"img/9.9967e563.png"},"4e3e":function(a,e,s){a.exports=s.p+"img/7.8099722a.svg"},"7aeb":function(a,e,s){a.exports=s.p+"img/13.5a065499.png"},"9bbd":function(a,e,s){a.exports=s.p+"img/19.540f007f.svg"},a268:function(a,e,s){a.exports=s.p+"img/12.48b5f287.png"},a6a0:function(a,e,s){a.exports=s.p+"img/16.5be7b527.png"},b080:function(a,e,s){a.exports=s.p+"img/17.2d3218b6.svg"},c589:function(a,e,s){a.exports=s.p+"img/8.e6614b1d.svg"},f388:function(a,e,s){a.exports=s.p+"img/5.f02a0a83.png"}}]);
//# sourceMappingURL=tema1.88df3a40.js.map